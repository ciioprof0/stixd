{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of STIX-D's Clex Importer Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Welcome to this demonstration of the Clex Importer tool. The Clex Importer is a specialized utility designed to seed the lexicon table in the STIX-D Corpus Database with the Attempto Controlled English (ACE) common lexicon. ACE is a controlled natural language that allows for unambiguous interpretation by both humans and machines, making it an essential component for applications requiring precise language processing.\n",
    "\n",
    "During this demonstration, we will walk through the process of importing the ACE common lexicon into the database. The tool reads the Clex lexicon file, parses its content, and systematically imports the lexical entries into the database. By the end of this demonstration, the `lexicon` table will be populated with sample entries to support ACE-based natural language processing tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "1. Use Case\n",
    "1. Project Design\n",
    "1. Code Interaction with Database\n",
    "1. Test Cases\n",
    "    - All Tests\n",
    "    - Unit Tests\n",
    "    - Integration Tests\n",
    "    - End-to-End Tests\n",
    "1. Code Execution\n",
    "    - Command Line Interface (in notebook)\n",
    "    - Web Interface (not in notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Use Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The STIX-D Use Case L1 involves seeding the `stixd_corpus.lexicon` database table with lexical entries from the ACE Common Lexicon (Clex) or similar files. An administrator provides a URI to the lexicon file, and the system connects to the local database via the `mysql_repository.py` module. For each line in the lexicon file, the system extracts relevant character strings to create a word tag and form, generates a SHA256 hash of these components, and checks for the hash in the `lexicon` table. If the hash exists, it links the existing entry with an existing source ID; if not, it creates a new entry. The system also imports additional arguments into appropriate fields and outputs summary information or error messages as necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Project Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Overview\n",
    "The Clex Importer tool imports lexical entries from the Attempto Controlled English (ACE) lexicon file, stored as Prolog facts, into the `lexicon` table of the STIX-D MySQL database. This tool is accessible via the command line or a web form served by a Flask API, where users input a URL pointing to an ACE lexicon file. The system then parses the each Prolog fact and maps it to the appropriate attributes in the `lexicon` table and creates relevant entries in the `stix_obects` table (i.e., source documents) and the `obj_lex_jt` juntion table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OOP Principles in the Project\n",
    "This project is designed using object-oriented programming (OOP) principles to create a modular, extensible, and maintainable system. The key OOP principles in the project are as follows:\n",
    "\n",
    "- **Abstraction**: The project uses abstract classes and methods to define interfaces and enforce a common structure. For example, the Repository class defines abstract methods for interacting with the database, which are implemented by MySQLRepository.\n",
    "- **Encapsulation**: Each class is responsible for a specific aspect of the project, encapsulating related data and behavior. For example, ClexImporter encapsulates the logic for importing Clex entries, while MySQLRepository encapsulates database interactions.\n",
    "- **Inheritance**: The project uses inheritance to create a hierarchy of classes with shared behavior. For example, MySQLRepository inherits from Repository to reuse common database interaction methods.\n",
    "- **Polymorphism**: The project uses polymorphism to allow different classes to be used interchangeably. For example, the Repository interface allows different types of repositories to be used with the ClexImporter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Modules and Their OOP Design\n",
    "The project consists of the following key modules, each designed using OOP principles:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **`ClexImporter` Class in `clex_importer.py`**: \n",
    "    - **Responsibility**: Manages the importation of Clex entries into the database.\n",
    "    - **Attributes**:\n",
    "        - `db_repo`: Represents the database repository where Clex entries will be stored.\n",
    "        - `uri`: The location of the Clex file to be imported.\n",
    "    - **Methods**:\n",
    "        - `import_clex_entries()`: Imports Clex entries from the specified file into the database.\n",
    "        - `parse_clex_entry()`: Parses a single Clex entry from the file.\n",
    "        - `map_clex_entry_to_lexicon()`: Maps the parsed Clex entry to the `lexicon` table schema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **`MySQLRepository` Class in `mysql_repository.py`**: \n",
    "    - **Responsibility**: Abstracts the database interactions for MySQL databases.\n",
    "    - **Attributes**:\n",
    "        - `connection`: Represents the connection to the MySQL database.\n",
    "        - `table_name`: The name of the table in the database.\n",
    "    - **Methods**:\n",
    "        - `create_table()`: Creates the table in the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **MySQLRepository**: Contains the MySQLRepository class, which implements the Repository interface for interacting with a MySQL database. The class uses the mysql-connector-python library to connect to the database and execute queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Code Interaction with the Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Notebook Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Necessary Packages\n",
    "\n",
    "If you are running this notebook for the first time, uncomment the code cell below or run the command from your terminal to install the necessary Python packages for this demonstration notebook. Once you have installed the packages, please re-comment the code cell for a cleaner notebook interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r ../demos/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Cases\n",
    "\n",
    "In this section, we explore and demonstrate the comprehensive testing strategy employed in the project, which includes various types of test cases to ensure the reliability and correctness of the implemented code. The test suite consists of unit tests, which validate individual components such as database operations, NLP processing, and web scraping functionalities; integration tests, which check the interactions between different modules; and end-to-end tests, which simulate real user workflows to ensure the entire application behaves as expected from front-end to back-end. By running all tests together or focusing on specific ones, these test cases provide a robust framework for identifying and addressing issues, ensuring the system functions correctly across different scenarios and use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries & Set Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    }
   ],
   "source": [
    "# Import Standard Libraries\n",
    "import os, sys, pytest\n",
    "# from IPython.display import IFrame, display\n",
    "\n",
    "# Get the current working directory (CWD)\n",
    "cwd = os.getcwd()\n",
    "# Move up two levels to reach the stixd directory\n",
    "stixd_path = os.path.abspath(os.path.join(cwd, '..', '..'))\n",
    "# Append the stixd directory to the Python path\n",
    "sys.path.append(stixd_path)\n",
    "\n",
    "# Load Jupyter Notebook extensions\n",
    "%load_ext sql\n",
    "\n",
    "# Define Global Variables\n",
    "TEST_DIR = os.path.join(os.getcwd(), '../tests')\n",
    "VERBOSITY = '-q' # Quiet\n",
    "TRACEBACK = '--tb=line' # One line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "%sql mysql+mysqlconnector://your_username:your_password@localhost:3306/stixd_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Test Cases\n",
    "\n",
    "You can quickly run all the tests in the STIX-D project, including those outside of the Clex Importer tool, by executing the code snippet below. This command will execute every test case located in the test directory, providing a comprehensive check of the entire system in just 30-60 seconds. This is an efficient way to ensure that all components of the project are functioning as expected, and it is highly recommended to run this after making any significant changes to the codebase.\n",
    "\n",
    "Please note that one or both of the end-to-end (e2e) test cases may fail sometimes but often pass if you run the test(s) again. If the e2e test(s) fails twice in a row, try restarting the notebook kernel and rerun the test. This intermittent failure is likely due to a race condition in this notebook environment that does not manifest in a typical local environment. I will continue to investigate this issue to provide a more stable testing experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                         [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m32 passed\u001b[0m\u001b[32m in 43.01s\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run all tests in the test directory (~30-60 seconds)\n",
    "pytest.main([TEST_DIR, VERBOSITY, TRACEBACK])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit Tests\n",
    "\n",
    "Unit tests are designed to validate the functionality of individual components or methods within the system. These tests focus on specific, isolated parts of the code, ensuring that each function or class behaves as expected under various conditions. Unit tests are the foundation of a robust testing strategy, catching issues early in the development process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Case 1: doc_scrapper\n",
    "\n",
    "The unit test case in the file `test_10_doc_scrapper.py` is designed to validate several key functions in a web scraping module. It includes tests for fetching HTML content from a URL using a mocked requests.get response, verifying if a webpage allows scraping by checking the presence of specific meta tags, converting HTML content to Markdown format, and saving the Markdown content to a file. The test suite utilizes fixtures for consistent HTML content, mocking to simulate file operations and HTTP requests, and asserts to ensure the correctness of the functions involved. Overall, the tests cover both functional aspects and edge cases of the web scraping process, ensuring that each component behaves as expected under controlled conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.12.4, pytest-8.3.2, pluggy-1.5.0 -- d:\\OneDrive\\Code\\hltms\\stixd\\.venv\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: d:\\OneDrive\\Code\\hltms\\stixd\n",
      "configfile: pytest.ini\n",
      "plugins: anyio-4.4.0, mock-3.14.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 5 items\n",
      "\n",
      "..\\tests\\test_10_doc_scrapper.py::test_fetch_html \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 20%]\u001b[0m\n",
      "..\\tests\\test_10_doc_scrapper.py::test_allows_scraping \u001b[32mPASSED\u001b[0m\u001b[32m            [ 40%]\u001b[0m\n",
      "..\\tests\\test_10_doc_scrapper.py::test_convert_html_to_markdown \u001b[32mPASSED\u001b[0m\u001b[32m   [ 60%]\u001b[0m\n",
      "..\\tests\\test_10_doc_scrapper.py::test_save_markdown \u001b[32mPASSED\u001b[0m\u001b[32m              [ 80%]\u001b[0m\n",
      "..\\tests\\test_10_doc_scrapper.py::test_process_url \u001b[32mPASSED\u001b[0m\u001b[32m                [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m5 passed\u001b[0m\u001b[32m in 0.20s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a specific test file in the test directory\n",
    "test_file = \"test_10_doc_scrapper.py\"\n",
    "pytest.main([os.path.join(TEST_DIR, test_file), \"-v\", \"--tb=auto\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Case 2: gen_clex_uuid\n",
    "\n",
    "The unit test case in the file test_20_gen_clex_uuid.py is designed to test the functionality of the generate_stix_uuid function, which generates STIX-compliant UUIDs based on the input parameters. The test utilizes parameterized test cases, where different combinations of UUID version, object type, and file URLs are passed to the function. It uses a mock for the requests.get function to simulate the retrieval of content from specified URLs without making actual network requests. The test verifies that the generated STIX identifiers have the correct format, including the specified object type prefix and a valid UUID. This ensures that the generate_stix_uuid function behaves correctly under different input scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.12.4, pytest-8.3.2, pluggy-1.5.0 -- d:\\OneDrive\\Code\\hltms\\stixd\\.venv\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: d:\\OneDrive\\Code\\hltms\\stixd\n",
      "configfile: pytest.ini\n",
      "plugins: anyio-4.4.0, mock-3.14.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "..\\tests\\test_20_gen_clex_uuid.py::test_generate_uuid[4-x-stixd-clex-https:\\raw.githubusercontent.com\\ciioprof0\\stixd\\03c934281777fecd3edb1d8622310bbf0839c17d\\tests\\test_clex.pl] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "..\\tests\\test_20_gen_clex_uuid.py::test_generate_uuid[4-x-stixd-clex-https:\\raw.githubusercontent.com\\Attempto\\Clex\\20960a5ce07776cb211a8cfb25dc8c81fcdf25e2\\clex_lexicon.pl] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.17s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a specific test file in the test directory\n",
    "test_file = \"test_20_gen_clex_uuid.py\"\n",
    "pytest.main([os.path.join(TEST_DIR, test_file), \"-v\", \"--tb=auto\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Case 3: mysql_repo\n",
    "\n",
    "The unit test case in the file `test_30_mysql_repo.py` is focused on testing the functionality of the `MySQLRepository` class, which is responsible for interacting with a MySQL database. The test suite includes several key tests: one for saving an entry into a database table and then loading it, and another for finding an entry by its ID (specifically by the `tag_form_hash`). The tests utilize mocking techniques to simulate database connections and operations, ensuring that the code interacts with the database correctly without needing an actual database connection. Assertions are made to verify that SQL queries are correctly executed and that the retrieved data matches the expected output. These tests ensure that the repository's methods function as intended in managing database entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.12.4, pytest-8.3.2, pluggy-1.5.0 -- d:\\OneDrive\\Code\\hltms\\stixd\\.venv\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: d:\\OneDrive\\Code\\hltms\\stixd\n",
      "configfile: pytest.ini\n",
      "plugins: anyio-4.4.0, mock-3.14.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "..\\tests\\test_30_mysql_repo.py::test_save_and_load_entry \u001b[32mPASSED\u001b[0m\u001b[32m          [ 50%]\u001b[0m\n",
      "..\\tests\\test_30_mysql_repo.py::test_find_entry_by_id \u001b[32mPASSED\u001b[0m\u001b[32m             [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.09s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a specific test file in the test directory\n",
    "test_file = \"test_30_mysql_repo.py\"\n",
    "pytest.main([os.path.join(TEST_DIR, test_file), \"-v\", \"--tb=auto\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Case 4: nlp_manager\n",
    "\n",
    "The unit test case in the file `test_40_nlp_manager.py` is designed to test the `NLPManager` class, which is part of an NLP (Natural Language Processing) pipeline. The test suite includes tests for two main methods: `process_text` and `process_sentence`. Both tests utilize mocking to simulate the behavior of these methods within the `NLPManager` class. The `process_text` test checks that the method correctly processes a block of text and returns both the processed text and associated metadata. Similarly, the `process_sentence` test ensures that the method processes a single sentence and returns the expected data structure. These tests help confirm that the `NLPManager` class performs its text and sentence processing tasks accurately, even when integrated with other components of the NLP pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.12.4, pytest-8.3.2, pluggy-1.5.0 -- d:\\OneDrive\\Code\\hltms\\stixd\\.venv\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: d:\\OneDrive\\Code\\hltms\\stixd\n",
      "configfile: pytest.ini\n",
      "plugins: anyio-4.4.0, mock-3.14.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "..\\tests\\test_40_nlp_manager.py::test_process_text \u001b[32mPASSED\u001b[0m\u001b[32m                [ 50%]\u001b[0m\n",
      "..\\tests\\test_40_nlp_manager.py::test_process_sentence \u001b[32mPASSED\u001b[0m\u001b[32m            [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.08s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a specific test file in the test directory\n",
    "test_file = \"test_40_nlp_manager.py\"\n",
    "pytest.main([os.path.join(TEST_DIR, test_file), \"-v\", \"--tb=auto\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Case 5: doc_manager\n",
    "\n",
    "The unit test case in the file `test_50_doc_manager.py` is designed to validate the functionality of the `DocumentManager` class, which is responsible for managing documents within a database. The test suite includes three key tests: `test_create_document`, `test_link_document`, and `test_process_document_text`. Each test uses mocking to simulate the database connection and operations without requiring a real database. The `test_create_document` ensures that a new STIX object is correctly inserted into the `documents` table. The `test_link_document` verifies that the correct association between a STIX ID and a document ID is made in the join table. Lastly, `test_process_document_text` checks that the document text is processed by the `NLPManager` and the resulting processed text and metadata are accurately updated in the database. These tests ensure that the `DocumentManager` performs its tasks of creating, linking, and processing documents effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.12.4, pytest-8.3.2, pluggy-1.5.0 -- d:\\OneDrive\\Code\\hltms\\stixd\\.venv\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: d:\\OneDrive\\Code\\hltms\\stixd\n",
      "configfile: pytest.ini\n",
      "plugins: anyio-4.4.0, mock-3.14.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 3 items\n",
      "\n",
      "..\\tests\\test_50_doc_manager.py::test_create_document \u001b[32mPASSED\u001b[0m\u001b[32m             [ 33%]\u001b[0m\n",
      "..\\tests\\test_50_doc_manager.py::test_link_document \u001b[32mPASSED\u001b[0m\u001b[32m               [ 66%]\u001b[0m\n",
      "..\\tests\\test_50_doc_manager.py::test_process_document_text \u001b[32mPASSED\u001b[0m\u001b[32m       [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 0.11s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a specific test file in the test directory\n",
    "test_file = \"test_50_doc_manager.py\"\n",
    "pytest.main([os.path.join(TEST_DIR, test_file), \"-v\", \"--tb=auto\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Case 6: sent_manager\n",
    "\n",
    "The unit test case in the file `test_53_sent_manager.py` is designed to validate the functionality of the `SentenceManager` class, which manages sentences within a database context. The test suite includes three primary tests: `test_create_sentence`, `test_link_sentence`, and `test_process_sentence_text`. Each test uses mocking to simulate the database connection and operations, ensuring that the tests do not require a live database. The `test_create_sentence` ensures that a sentence associated with a specific document ID is correctly inserted into the `sentences` table. The `test_link_sentence` verifies that the relationship between a document and a sentence is accurately recorded in the join table. Lastly, `test_process_sentence_text` checks that the sentence is processed using the `NLPManager`, and the processed text is correctly updated in the database. These tests ensure that the `SentenceManager` class performs its roles of creating, linking, and processing sentences effectively and reliably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.12.4, pytest-8.3.2, pluggy-1.5.0 -- d:\\OneDrive\\Code\\hltms\\stixd\\.venv\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: d:\\OneDrive\\Code\\hltms\\stixd\n",
      "configfile: pytest.ini\n",
      "plugins: anyio-4.4.0, mock-3.14.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 3 items\n",
      "\n",
      "..\\tests\\test_53_sent_manager.py::test_create_sentence \u001b[32mPASSED\u001b[0m\u001b[32m            [ 33%]\u001b[0m\n",
      "..\\tests\\test_53_sent_manager.py::test_link_sentence \u001b[32mPASSED\u001b[0m\u001b[32m              [ 66%]\u001b[0m\n",
      "..\\tests\\test_53_sent_manager.py::test_process_sentence_text \u001b[32mPASSED\u001b[0m\u001b[32m      [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 0.12s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a specific test file in the test directory\n",
    "test_file = \"test_53_sent_manager.py\"\n",
    "pytest.main([os.path.join(TEST_DIR, test_file), \"-v\", \"--tb=auto\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Case 7: lexicon_manager\n",
    "\n",
    "The unit test case in the file `test_57_lexicon_manager.py` is designed to validate the functionality of the `LexiconManager` class, which is responsible for managing lexicon entries within a database. The test suite includes three primary tests: `test_create_lexicon_entry`, `test_link_lexicon_entry`, and `test_process_word`. These tests use mocking to simulate database connections and operations, ensuring they do not depend on a real database. The `test_create_lexicon_entry` verifies that a new word associated with a specific sentence ID is correctly inserted into the `lexicon` table. The `test_link_lexicon_entry` ensures that the relationship between a sentence and a lexicon entry is accurately recorded in the join table. Lastly, the `test_process_word` checks that a word is processed using the `NLPManager`, and the resulting processed word is correctly updated in the database. These tests ensure that the `LexiconManager` class performs its tasks of creating, linking, and processing lexicon entries effectively and reliably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.12.4, pytest-8.3.2, pluggy-1.5.0 -- d:\\OneDrive\\Code\\hltms\\stixd\\.venv\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: d:\\OneDrive\\Code\\hltms\\stixd\n",
      "configfile: pytest.ini\n",
      "plugins: anyio-4.4.0, mock-3.14.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 3 items\n",
      "\n",
      "..\\tests\\test_57_lexicon_manager.py::test_create_lexicon_entry \u001b[32mPASSED\u001b[0m\u001b[32m    [ 33%]\u001b[0m\n",
      "..\\tests\\test_57_lexicon_manager.py::test_link_lexicon_entry \u001b[32mPASSED\u001b[0m\u001b[32m      [ 66%]\u001b[0m\n",
      "..\\tests\\test_57_lexicon_manager.py::test_process_word \u001b[32mPASSED\u001b[0m\u001b[32m            [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 0.12s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a specific test file in the test directory\n",
    "test_file = \"test_57_lexicon_manager.py\"\n",
    "pytest.main([os.path.join(TEST_DIR, test_file), \"-v\", \"--tb=auto\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Case 8: clex_importer_local\n",
    "\n",
    "The unit test case in the file `test_70_clex_importer_local.py` is focused on testing the `ClexImporter` service layer, which is responsible for importing lexicon entries into a MySQL database from a specified Clex file. The test case utilizes parameterized inputs to check various scenarios, including different `lex_id`, `word_tag`, `word_form`, `logical_symbol`, `third_arg`, and `tag_form_hash` values. The test ensures that the `import_clex_entries` method of the `ClexImporter` correctly imports the data and that the entries are accurately stored in the `lexicon` table in the database. It validates this by querying the database after the import and comparing the results to the expected values. These tests ensure the reliability and correctness of the lexicon import process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.12.4, pytest-8.3.2, pluggy-1.5.0 -- d:\\OneDrive\\Code\\hltms\\stixd\\.venv\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: d:\\OneDrive\\Code\\hltms\\stixd\n",
      "configfile: pytest.ini\n",
      "plugins: anyio-4.4.0, mock-3.14.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 4 items\n",
      "\n",
      "..\\tests\\test_70_clex_importer_local.py::test_import_clex_entries[1-adv-fast-fast-None-67e9b1c5cbd53045919deda792be49b18b41a09b3bd328f9cc406bb27d951f62] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "..\\tests\\test_70_clex_importer_local.py::test_import_clex_entries[19-noun_pl-months-month-neutr-6e7ab17fe3f242d10f360197f40646b443db6079d730e9d746c96824a2606336] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "..\\tests\\test_70_clex_importer_local.py::test_import_clex_entries[39-iv_finsg-walks-walk-None-f02be7a15dcd7cca79dc9b1c141991d479120352658c50030c7268da9372e6ff] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "..\\tests\\test_70_clex_importer_local.py::test_import_clex_entries[58-dv_pp-succeeded-succeed-as-8ee745975fad537905042b710e2f602f6c6bbe6c72f123b3596ce0b962f2b23f] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================= \u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 10.60s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a specific test file in the test directory (~ 10 seconds)\n",
    "test_file = \"test_70_clex_importer_local.py\"\n",
    "pytest.main([os.path.join(TEST_DIR, test_file), \"-v\", \"--tb=auto\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Case 9: clex_importer_ci\n",
    "\n",
    "The unit test case in the file `test_75_clex_importer_ci.py` is designed to test the `import_clex_entries` method of the `ClexImporter` class, which is part of a system that imports Clex lexicon entries into a MySQL database. The test uses mocking to simulate the behavior of external dependencies, such as HTTP requests and UUID generation, as well as interactions with the database via the `MySQLRepository`. The test mocks an HTTP request to retrieve Clex data and verifies that the data is correctly parsed and stored in the database. It also checks that UUIDs are generated appropriately for each entry and that the database methods for saving and linking entries are called the expected number of times. These tests ensure that the `import_clex_entries` method performs as expected under controlled conditions, handling both data retrieval and database interactions effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.12.4, pytest-8.3.2, pluggy-1.5.0 -- d:\\OneDrive\\Code\\hltms\\stixd\\.venv\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: d:\\OneDrive\\Code\\hltms\\stixd\n",
      "configfile: pytest.ini\n",
      "plugins: anyio-4.4.0, mock-3.14.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "..\\tests\\test_75_clex_importer_ci.py::test_import_clex_entries \u001b[32mPASSED\u001b[0m\u001b[32m    [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.09s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a specific test file in the test directory\n",
    "test_file = \"test_75_clex_importer_ci.py\"\n",
    "pytest.main([os.path.join(TEST_DIR, test_file), \"-v\", \"--tb=auto\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration Tests\n",
    "\n",
    "End-to-End tests simulate real user interactions with the entire system, testing the complete workflow from start to finish. These tests ensure that the application functions correctly as a whole, from the user interface down to the underlying database operations, replicating the experience of an actual user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Case 10: api\n",
    "\n",
    "The unit test case in the file `test_80_api.py` is focused on testing the `/import_clex` endpoint of a Flask API, which is responsible for handling requests to import Clex lexicon entries. The test suite uses mocking to simulate the behavior of the `ClexImporter` and `MySQLRepository` classes, ensuring that the tests do not rely on external systems. Several scenarios are tested: a successful import, a bad request with missing or invalid data, handling of general exceptions during the import process, MySQL-specific errors, and system-level errors like `OSError`. The tests verify that the API responds with the correct HTTP status codes and JSON messages depending on the situation, ensuring robust error handling and correct functionality of the API endpoint under various conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.12.4, pytest-8.3.2, pluggy-1.5.0 -- d:\\OneDrive\\Code\\hltms\\stixd\\.venv\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: d:\\OneDrive\\Code\\hltms\\stixd\n",
      "configfile: pytest.ini\n",
      "plugins: anyio-4.4.0, mock-3.14.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 5 items\n",
      "\n",
      "..\\tests\\test_80_api.py::test_import_clex_success \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 20%]\u001b[0m\n",
      "..\\tests\\test_80_api.py::test_import_clex_bad_request \u001b[32mPASSED\u001b[0m\u001b[32m             [ 40%]\u001b[0m\n",
      "..\\tests\\test_80_api.py::test_import_clex_request_exception \u001b[32mPASSED\u001b[0m\u001b[32m       [ 60%]\u001b[0m\n",
      "..\\tests\\test_80_api.py::test_import_clex_mysql_error \u001b[32mPASSED\u001b[0m\u001b[32m             [ 80%]\u001b[0m\n",
      "..\\tests\\test_80_api.py::test_import_clex_system_error \u001b[32mPASSED\u001b[0m\u001b[32m            [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m5 passed\u001b[0m\u001b[32m in 0.12s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a specific test file in the test directory\n",
    "test_file = \"test_80_api.py\"\n",
    "pytest.main([os.path.join(TEST_DIR, test_file), \"-v\", \"--tb=auto\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End-to-End Tests\n",
    "\n",
    "End-to-End tests simulate real user interactions with the entire system, testing the complete workflow from start to finish. These tests ensure that the application functions correctly as a whole, from the user interface down to the underlying database operations, replicating the experience of an actual user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Case 11: e2e_local\n",
    "\n",
    "The unit test case in the file `test_90_e2e_local.py` is an end-to-end (E2E) test for a Flask web application, focusing on verifying the full functionality of the app from the user's perspective. The test uses Selenium WebDriver to automate interactions with a web form that allows users to submit a URI for importing Clex lexicon entries. The test includes setting up the Flask application in a separate process, initializing the Selenium WebDriver with specific options, interacting with the form by filling it out and submitting it, and capturing the response from the application to assert that the operation was successful. The E2E test ensures that the integration of the front-end and back-end components works as expected, simulating real user behavior and validating the complete workflow of the form submission process.\n",
    "\n",
    "Please note that one or both of the end-to-end (e2e) test cases may fail sometimes and often pass if you run the test(s) again. If the e2e test(s) fails twice in a row, try restarting the notebook kernel and rerun the test(s). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.12.4, pytest-8.3.2, pluggy-1.5.0 -- d:\\OneDrive\\Code\\hltms\\stixd\\.venv\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: d:\\OneDrive\\Code\\hltms\\stixd\n",
      "configfile: pytest.ini\n",
      "plugins: anyio-4.4.0, mock-3.14.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "..\\tests\\test_90_e2e_local.py::test_form_submission \u001b[32mPASSED\u001b[0m\u001b[32m               [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================= \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 17.35s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a specific test file in the test directory (~15 seconds)\n",
    "test_file = \"test_90_e2e_local.py\"\n",
    "pytest.main([os.path.join(TEST_DIR, test_file), \"-v\", \"--tb=auto\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Case 12: e2e_ci\n",
    "\n",
    "The unit test case in the file `test_95_e2e_ci.py` is an end-to-end (E2E) test designed to verify the complete functionality of a Flask web application as it would be executed in a continuous integration (CI) environment. Similar to the local E2E test, this test uses Selenium WebDriver to automate browser interactions, simulating a user submitting a form on the web interface of the application. The test involves starting the Flask app in a separate process, interacting with the form by inputting a URI, submitting it, and then checking the response to ensure that the process completes successfully with the expected output (\"Import successful\"). This test ensures that the web application works correctly in a CI environment, validating the entire user journey from form submission to the final response.\n",
    "\n",
    "Please note that one or both of the end-to-end (e2e) test cases may fail sometimes and often pass if you run the test(s) again. If the e2e test(s) fails twice in a row, try restarting the notebook kernel and rerun the test(s). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.12.4, pytest-8.3.2, pluggy-1.5.0 -- d:\\OneDrive\\Code\\hltms\\stixd\\.venv\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: d:\\OneDrive\\Code\\hltms\\stixd\n",
      "configfile: pytest.ini\n",
      "plugins: anyio-4.4.0, mock-3.14.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "..\\tests\\test_95_e2e_ci.py::test_form_submission \u001b[32mPASSED\u001b[0m\u001b[32m                  [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================= \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 17.55s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a specific test file in the test directory (~15 seconds)\n",
    "test_file = \"test_95_e2e_ci.py\"\n",
    "pytest.main([os.path.join(TEST_DIR, test_file), \"-v\", \"--tb=auto\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Code Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " When running the code cell below to reset the database, you may encounter `Error: 1064 (42000)`.\n",
    " \n",
    "This error occurs because the MySQL `DELIMITER` command is not recognized by the `mysql.connector` library used in Python. Despite this error, the SQL script executes as intended. The error can be safely ignored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'DELIMITER ;\n",
      "\n",
      "\n",
      "-- Create procedure to check for prolog constraints (sp_check_prol' at line 1\n"
     ]
    }
   ],
   "source": [
    "# Reset the database to start with an empty database\n",
    "%run ../app/reset_database.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Database Initial State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After resetting the database, all tables should be empty. Let's verify the initial state of the database by running a query to select all entries from the three tables affected by the Clex Importer tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+mysqlconnector://your_username:***@localhost:3306/stixd_corpus\n",
      "1 rows affected.\n",
      " * mysql+mysqlconnector://your_username:***@localhost:3306/stixd_corpus\n",
      "1 rows affected.\n",
      " * mysql+mysqlconnector://your_username:***@localhost:3306/stixd_corpus\n",
      "1 rows affected.\n",
      "\n",
      "Rows in 'stix_objects' table:  0\n",
      "Rows in 'lexicon' table:       0\n",
      "Rows in 'obj_lex_jt' table:    0\n"
     ]
    }
   ],
   "source": [
    "# Fetch table counts\n",
    "lexicon_count = %sql SELECT COUNT(*) FROM lexicon;\n",
    "stix_objects_count = %sql SELECT COUNT(*) FROM stix_objects;\n",
    "obj_lex_jt_count = %sql SELECT COUNT(*) FROM obj_lex_jt;\n",
    "\n",
    "# Display number of rows in each table\n",
    "print(f\"\\nRows in 'stix_objects' table:  {stix_objects_count[0][0]}\\n\"\n",
    "      f\"Rows in 'lexicon' table:       {lexicon_count[0][0]}\\n\"\n",
    "      f\"Rows in 'obj_lex_jt' table:    {obj_lex_jt_count[0][0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution from Command Line\n",
    "\n",
    "The Clex Importer tool can be executed from the command line. The following command demonstrates how to run the Clex Importer tool from the command line:\n",
    "\n",
    "    `python clex_importer.py --uri <URL_TO_CLEX_FILE>`\n",
    "\n",
    "- After a database reset, expect 62 total entries with 59 new and 3 existing entries\n",
    "- Without a database reset, expect 62 total entries with 0 new and 62 existing entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved STIX object with ID: x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 67e9b1c5cbd53045919deda792be49b18b41a09b3bd328f9cc406bb27d951f62 for adv - fast\n",
      "Inserted entry with lex_id: 1 into lexicon\n",
      "Linking lex_id 1 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 1 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 38a31bf0527ff6fd23c6be74bfba58c46dbad709ce90b6d09b9a26f103a326b5 for adv_comp - faster\n",
      "Inserted entry with lex_id: 2 into lexicon\n",
      "Linking lex_id 2 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 2 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 55fee0f355e343b2c6a4d63b72a8ea8bcaa1a71698ada04e01533a8dc98fb4ee for adv_sup - fastest\n",
      "Inserted entry with lex_id: 3 into lexicon\n",
      "Linking lex_id 3 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 3 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: b0a248290b9aa18bfbbbfd5367dc0cc0dc82a9e90dd83b88cce59361b8d67e8a for adv - quickly\n",
      "Inserted entry with lex_id: 4 into lexicon\n",
      "Linking lex_id 4 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 4 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: bbe9bafa7a2a6e250fdf482a7c46217d7c63ccee917b3ae48324b61659c7e32d for adj_itr - large\n",
      "Inserted entry with lex_id: 5 into lexicon\n",
      "Linking lex_id 5 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 5 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: bf10c6415fdedfef6bb41e276ee11b5411b9735e04279a725fd1e10f73efd5a3 for adj_itr_comp - larger\n",
      "Inserted entry with lex_id: 6 into lexicon\n",
      "Linking lex_id 6 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 6 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 272e32e00264453eae65c42e85ebd4e63d2050652adf2a83e6251f58d44c1f80 for adj_itr_sup - largest\n",
      "Inserted entry with lex_id: 7 into lexicon\n",
      "Linking lex_id 7 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 7 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 0a071608bacedfe582720a7eac91a086c2fd4b8310886756596e55a19831f1b2 for adj_itr - expensive\n",
      "Inserted entry with lex_id: 8 into lexicon\n",
      "Linking lex_id 8 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 8 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 3185ec15fd8fee48b0ce5f3cf0702e7342b8a79e924b9560672d46f85b57cf0d for adj_tr - valid-for\n",
      "Inserted entry with lex_id: 9 into lexicon\n",
      "Linking lex_id 9 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 9 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: bea4050ddc4a98586180049a5701670bfda43dfb33a9e9d439e09ea6658d8b49 for adj_tr - fond-of\n",
      "Inserted entry with lex_id: 10 into lexicon\n",
      "Linking lex_id 10 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 10 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: f9af59d37b5027585c5c367ff09c9ae6c9a9c2a572f0c2c6e31cb7a477803f70 for adj_tr_comp - fonder-of\n",
      "Inserted entry with lex_id: 11 into lexicon\n",
      "Linking lex_id 11 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 11 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 0593075d289bc5204293471f2179dcb02b688666ab3f0609dc0707038bda6c19 for adj_tr_sup - fondest-of\n",
      "Inserted entry with lex_id: 12 into lexicon\n",
      "Linking lex_id 12 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 12 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: ad8d6c20f19057bc423efd798ab1b7969e8d16b84175a5e1c8d6327f301c3555 for adj_tr - pessimistic-about\n",
      "Inserted entry with lex_id: 13 into lexicon\n",
      "Linking lex_id 13 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 13 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 81a4335048050be30cbe511f20aa06edd43edeace4e509c9dbe295d91f3d7c67 for noun_sg - woman\n",
      "Inserted entry with lex_id: 14 into lexicon\n",
      "Linking lex_id 14 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 14 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: d94e7754776de6a607bd1401e97542788b8a5bcdd770a6743029ba3cb9281e9b for noun_pl - women\n",
      "Inserted entry with lex_id: 15 into lexicon\n",
      "Linking lex_id 15 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 15 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 3e750200b57ae141249f9a284aa994912f051b9cdaaabce0eab54d8f709786b4 for noun_sg - credit-card\n",
      "Inserted entry with lex_id: 16 into lexicon\n",
      "Linking lex_id 16 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 16 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: ba1d673f62b614589363b57193e41fff0a55c16496de3390cd4bdebe05b66a5f for noun_pl - credit-cards\n",
      "Inserted entry with lex_id: 17 into lexicon\n",
      "Linking lex_id 17 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 17 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 7dd815d8b271ce4a800d0709cc47e4542ae83c20580fad16f0ce0ac47ab825cb for noun_sg - month\n",
      "Inserted entry with lex_id: 18 into lexicon\n",
      "Linking lex_id 18 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 18 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 6e7ab17fe3f242d10f360197f40646b443db6079d730e9d746c96824a2606336 for noun_pl - months\n",
      "Inserted entry with lex_id: 19 into lexicon\n",
      "Linking lex_id 19 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 19 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: ab4b87413dcf986e3987394af66d8cd5b721d6e2e3414f0bf79b7180c496cffc for noun_mass - water\n",
      "Inserted entry with lex_id: 20 into lexicon\n",
      "Linking lex_id 20 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 20 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 1f47f35dd555019a4069f9ccbd73b6ca9aba50e65cba190c6c2234a0ec959550 for noun_mass - fear\n",
      "Inserted entry with lex_id: 21 into lexicon\n",
      "Linking lex_id 21 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 21 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 54eb36da1c2712a561a7f3d97ae4711be26e689a610a5b3bcc6cf8246b4bd328 for noun_mass - money\n",
      "Inserted entry with lex_id: 22 into lexicon\n",
      "Linking lex_id 22 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 22 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: f0f05c2c9d5fbbca1a49caaf36e02cabd3e8008b6ba2e06dd4f3ad5af3fc6778 for mn_sg - kg\n",
      "Inserted entry with lex_id: 23 into lexicon\n",
      "Linking lex_id 23 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 23 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 4062f60546af1df473dca3885c5678bceba6f846a393bde85c9f062dd7b3e4e9 for mn_pl - kg\n",
      "Inserted entry with lex_id: 24 into lexicon\n",
      "Linking lex_id 24 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 24 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 355a5ac057c3579401933c1edab57acd83c4fff5af52b235fe6a6487740e7266 for mn_sg - m\n",
      "Inserted entry with lex_id: 25 into lexicon\n",
      "Linking lex_id 25 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 25 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: bd00a278eb02fcda5e6953929b33fb7b722616288a41ffec7e161932b00a4f28 for mn_pl - m\n",
      "Inserted entry with lex_id: 26 into lexicon\n",
      "Linking lex_id 26 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 26 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 4dbd3783cd9aaba7e2c7b91cd8b7528fe090214cf231c438a2bbce6c469eae54 for mn_sg - °C\n",
      "Inserted entry with lex_id: 27 into lexicon\n",
      "Linking lex_id 27 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 27 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 0b159623ff61b9c0c6dcbade8aecbcf5a3ba43a5c78a7353af9d4fc9a89d387b for mn_pl - °C\n",
      "Inserted entry with lex_id: 28 into lexicon\n",
      "Linking lex_id 28 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 28 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: cdb8203c69d244b96d0efc358b21bb7ecdfedaa377fc2d22174d202d514b60bd for pn_sg - John\n",
      "Inserted entry with lex_id: 29 into lexicon\n",
      "Linking lex_id 29 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 29 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: c362d3b6c8f1563be3031c9a27e83307499ef757668783df75d1c2ade5a8dcdb for pn_sg - Nokia\n",
      "Inserted entry with lex_id: 30 into lexicon\n",
      "Linking lex_id 30 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 30 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: b79f2d1e7257a89546b59cb6384c316c6a67b9090e0eb79e4945ab5203c5fcca for pndef_sg - Nile\n",
      "Inserted entry with lex_id: 31 into lexicon\n",
      "Linking lex_id 31 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 31 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 0ba13f88729a6598583fd0d63c2c946bbefb8e7084b49d1a6add9c13cd87615c for pndef_pl - United-Nations\n",
      "Inserted entry with lex_id: 32 into lexicon\n",
      "Linking lex_id 32 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 32 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: ab1d4ceef2dea8b6524e093ed881a9b373c7399fdda1238c6d6a50e45cb2e5c1 for pn_sg - Mona-Lisa\n",
      "Inserted entry with lex_id: 33 into lexicon\n",
      "Linking lex_id 33 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 33 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 553a63ea05f5be1335cdbaf4776e9fefe7b739709bde3afbc52d13f90d7f0747 for pndef_sg - Mona-Lisa\n",
      "Inserted entry with lex_id: 34 into lexicon\n",
      "Linking lex_id 34 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 34 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: ac7502fa73fb93115da3fdc332c095b93db172fb3c9da5342cb1d4efea1dbfa4 for iv_finsg - waits\n",
      "Inserted entry with lex_id: 35 into lexicon\n",
      "Linking lex_id 35 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 35 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: efb99022f10de88cfa917fd5f2d22db31a264c47c446e39b745ecaf2104386d5 for iv_infpl - wait\n",
      "Inserted entry with lex_id: 36 into lexicon\n",
      "Linking lex_id 36 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 36 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 43b09b0fdca3918fdeffbdd00f9b9b1e36680a19e18a27b9ef837250aea760ff for iv_finsg - goes-away\n",
      "Inserted entry with lex_id: 37 into lexicon\n",
      "Linking lex_id 37 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 37 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: ecc9360327520149b50d67f39339a5340963d1f856c8e2379694e5758b18b90f for iv_infpl - go-away\n",
      "Inserted entry with lex_id: 38 into lexicon\n",
      "Linking lex_id 38 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 38 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: f02be7a15dcd7cca79dc9b1c141991d479120352658c50030c7268da9372e6ff for iv_finsg - walks\n",
      "Inserted entry with lex_id: 39 into lexicon\n",
      "Linking lex_id 39 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 39 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 31e757a6e9e9b7a3e8b7760ed46a8d8fac08fa4989bd1e2564178a466592fb0b for iv_infpl - walk\n",
      "Inserted entry with lex_id: 40 into lexicon\n",
      "Linking lex_id 40 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 40 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: ee65aeba7add7b5c2bec1c8453b46d0686c74980f5b66e971d8e0fdf4be2f339 for tv_finsg - knows\n",
      "Inserted entry with lex_id: 41 into lexicon\n",
      "Linking lex_id 41 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 41 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 422c3c3b73090cafb154a7af0c97a4a8b6526d0c081ecfd3c4852555ca497274 for tv_infpl - know\n",
      "Inserted entry with lex_id: 42 into lexicon\n",
      "Linking lex_id 42 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 42 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 77ca0e15adaec7eb9f1e2b265d8c4aaea36eb3233610413ec08cbd2cc9e75602 for tv_pp - known\n",
      "Inserted entry with lex_id: 43 into lexicon\n",
      "Linking lex_id 43 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 43 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: f7e5589db0c1cd8731249783f142502b70a9c4c81f2438a1a68d9a14466d7638 for tv_finsg - likes\n",
      "Inserted entry with lex_id: 44 into lexicon\n",
      "Linking lex_id 44 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 44 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 5662a9d8c3e47a4030ee3ce04f64b96d20f97050b43889b9c99a3d75bdcf2e87 for tv_infpl - like\n",
      "Inserted entry with lex_id: 45 into lexicon\n",
      "Linking lex_id 45 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 45 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: f4758877070e53c2c6289823abd379e18f73118cf9427ba32004de974786bd71 for tv_pp - liked\n",
      "Inserted entry with lex_id: 46 into lexicon\n",
      "Linking lex_id 46 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 46 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: ee6ebaf5ffc016337f2f65c9331f36a1fbe639b1f78ae0447d006d28d8056028 for tv_finsg - relates-to\n",
      "Inserted entry with lex_id: 47 into lexicon\n",
      "Linking lex_id 47 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 47 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 192eda123579168e6bd639ed1df16c5698e593c45a353c7dac8e4ba71a910a72 for tv_infpl - relate-to\n",
      "Inserted entry with lex_id: 48 into lexicon\n",
      "Linking lex_id 48 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 48 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 90837f23fb3398bbf7acd13a4734d872ad7561a56638f7d02aef58af5f950656 for tv_pp - related-to\n",
      "Inserted entry with lex_id: 49 into lexicon\n",
      "Linking lex_id 49 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 49 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 42f5f444d7d957ad84c5a633757577db59591b988579f53bd1f350baddaf9f03 for dv_finsg - shows\n",
      "Inserted entry with lex_id: 50 into lexicon\n",
      "Linking lex_id 50 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 50 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: d14f9f05e5a0b45180e21ff9b1e2fbe467d23276236aa52fb37eb73fd340da91 for dv_infpl - show\n",
      "Inserted entry with lex_id: 51 into lexicon\n",
      "Linking lex_id 51 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 51 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 7cf576b300bbb026e4a7b5b4a8d792dc0f6e834354a4efe471977f2d71517a9a for dv_pp - shown\n",
      "Inserted entry with lex_id: 52 into lexicon\n",
      "Linking lex_id 52 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 52 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 42f5f444d7d957ad84c5a633757577db59591b988579f53bd1f350baddaf9f03 for dv_finsg - shows\n",
      "Entry already exists for hash: 42f5f444d7d957ad84c5a633757577db59591b988579f53bd1f350baddaf9f03\n",
      "Generated hash: d14f9f05e5a0b45180e21ff9b1e2fbe467d23276236aa52fb37eb73fd340da91 for dv_infpl - show\n",
      "Entry already exists for hash: d14f9f05e5a0b45180e21ff9b1e2fbe467d23276236aa52fb37eb73fd340da91\n",
      "Generated hash: 7cf576b300bbb026e4a7b5b4a8d792dc0f6e834354a4efe471977f2d71517a9a for dv_pp - shown\n",
      "Entry already exists for hash: 7cf576b300bbb026e4a7b5b4a8d792dc0f6e834354a4efe471977f2d71517a9a\n",
      "Generated hash: 4b9730c9ceecf1d5f810a4826903bb059c3e92371075ace397c16ed7d738418d for dv_finsg - forgives\n",
      "Inserted entry with lex_id: 53 into lexicon\n",
      "Linking lex_id 53 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 53 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 9b948431ccbbc7fe72acc6521239aa45db87345868a085fef14be2952cf73343 for dv_infpl - forgive\n",
      "Inserted entry with lex_id: 54 into lexicon\n",
      "Linking lex_id 54 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 54 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 87c13947298aa7164ca11f17ffb7cf6e0725519849e9cd3b369c99e69db9f417 for dv_pp - forgiven\n",
      "Inserted entry with lex_id: 55 into lexicon\n",
      "Linking lex_id 55 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 55 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 1b1a64cc34090572aa43370164020fb77fe5e26ea27e6841fb5da311c70db49e for dv_finsg - succeeds\n",
      "Inserted entry with lex_id: 56 into lexicon\n",
      "Linking lex_id 56 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 56 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 94cd50411086a27d99e36cea494fca14e31bfcdde6608e91b7d21b8abbfcba24 for dv_infpl - succeed\n",
      "Inserted entry with lex_id: 57 into lexicon\n",
      "Linking lex_id 57 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 57 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 8ee745975fad537905042b710e2f602f6c6bbe6c72f123b3596ce0b962f2b23f for dv_pp - succeeded\n",
      "Inserted entry with lex_id: 58 into lexicon\n",
      "Linking lex_id 58 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 58 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Generated hash: 49416a90f7e5b5ab216b186657fa6a7e5219aaa07c0d4fc0dfa1373b2f2663b9 for prep - in\n",
      "Inserted entry with lex_id: 59 into lexicon\n",
      "Linking lex_id 59 with stix_object_id x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Successfully linked lex_id 59 with stix_uuid x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255\n",
      "Import successful.\n",
      "New entries imported:    59\n",
      "Existing entries linked: 3\n",
      "===============================\n",
      "Total entries processed: 62\n"
     ]
    }
   ],
   "source": [
    "%run ../app/clex_importer.py \"https://github.com/ciioprof0/stixd/raw/main/lexicon/test_clex.pl\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Database State After Code Execution\n",
    "\n",
    "After running the Clex Importer tool, the tables below should have the expected number of rows. \n",
    "\n",
    "- Rows in 'stix_objects' table: 1 \n",
    "- Rows in 'lexicon' table:     59 \n",
    "- Rows in 'obj_lex_jt' table:  59\n",
    "\n",
    "Let's verify the state of the database by running a query to count entries in each table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+mysqlconnector://your_username:***@localhost:3306/stixd_corpus\n",
      "1 rows affected.\n",
      " * mysql+mysqlconnector://your_username:***@localhost:3306/stixd_corpus\n",
      "1 rows affected.\n",
      " * mysql+mysqlconnector://your_username:***@localhost:3306/stixd_corpus\n",
      "1 rows affected.\n",
      "\n",
      "Rows in 'stix_objects' table:  1\n",
      "Rows in 'lexicon' table:      59\n",
      "Rows in 'obj_lex_jt' table:   59\n"
     ]
    }
   ],
   "source": [
    "# Fetch table counts\n",
    "lexicon_count = %sql SELECT COUNT(*) FROM lexicon;\n",
    "stix_objects_count = %sql SELECT COUNT(*) FROM stix_objects;\n",
    "obj_lex_jt_count = %sql SELECT COUNT(*) FROM obj_lex_jt;\n",
    "\n",
    "# Display number of rows in each table\n",
    "print(f\"\\nRows in 'stix_objects' table:  {stix_objects_count[0][0]}\\n\"\n",
    "      f\"Rows in 'lexicon' table:      {lexicon_count[0][0]}\\n\"\n",
    "      f\"Rows in 'obj_lex_jt' table:   {obj_lex_jt_count[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also display a sample of the first five entries in each table to demonstrate the successful importation of Clex entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+mysqlconnector://your_username:***@localhost:3306/stixd_corpus\n",
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>lex_id</th>\n",
       "            <th>word_tag</th>\n",
       "            <th>word_form</th>\n",
       "            <th>logical_symbol</th>\n",
       "            <th>third_arg</th>\n",
       "            <th>tag_form_hash</th>\n",
       "            <th>word_def</th>\n",
       "            <th>synsets</th>\n",
       "            <th>tagsets</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>1</td>\n",
       "            <td>adv</td>\n",
       "            <td>fast</td>\n",
       "            <td>fast</td>\n",
       "            <td>NULL</td>\n",
       "            <td>67e9b1c5cbd53045919deda792be49b18b41a09b3bd328f9cc406bb27d951f62</td>\n",
       "            <td>None</td>\n",
       "            <td>None</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2</td>\n",
       "            <td>adv_comp</td>\n",
       "            <td>faster</td>\n",
       "            <td>fast</td>\n",
       "            <td>NULL</td>\n",
       "            <td>38a31bf0527ff6fd23c6be74bfba58c46dbad709ce90b6d09b9a26f103a326b5</td>\n",
       "            <td>None</td>\n",
       "            <td>None</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3</td>\n",
       "            <td>adv_sup</td>\n",
       "            <td>fastest</td>\n",
       "            <td>fast</td>\n",
       "            <td>NULL</td>\n",
       "            <td>55fee0f355e343b2c6a4d63b72a8ea8bcaa1a71698ada04e01533a8dc98fb4ee</td>\n",
       "            <td>None</td>\n",
       "            <td>None</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>4</td>\n",
       "            <td>adv</td>\n",
       "            <td>quickly</td>\n",
       "            <td>quickly</td>\n",
       "            <td>NULL</td>\n",
       "            <td>b0a248290b9aa18bfbbbfd5367dc0cc0dc82a9e90dd83b88cce59361b8d67e8a</td>\n",
       "            <td>None</td>\n",
       "            <td>None</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>5</td>\n",
       "            <td>adj_itr</td>\n",
       "            <td>large</td>\n",
       "            <td>large</td>\n",
       "            <td>NULL</td>\n",
       "            <td>bbe9bafa7a2a6e250fdf482a7c46217d7c63ccee917b3ae48324b61659c7e32d</td>\n",
       "            <td>None</td>\n",
       "            <td>None</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(1, 'adv', 'fast', 'fast', 'NULL', '67e9b1c5cbd53045919deda792be49b18b41a09b3bd328f9cc406bb27d951f62', None, None, None),\n",
       " (2, 'adv_comp', 'faster', 'fast', 'NULL', '38a31bf0527ff6fd23c6be74bfba58c46dbad709ce90b6d09b9a26f103a326b5', None, None, None),\n",
       " (3, 'adv_sup', 'fastest', 'fast', 'NULL', '55fee0f355e343b2c6a4d63b72a8ea8bcaa1a71698ada04e01533a8dc98fb4ee', None, None, None),\n",
       " (4, 'adv', 'quickly', 'quickly', 'NULL', 'b0a248290b9aa18bfbbbfd5367dc0cc0dc82a9e90dd83b88cce59361b8d67e8a', None, None, None),\n",
       " (5, 'adj_itr', 'large', 'large', 'NULL', 'bbe9bafa7a2a6e250fdf482a7c46217d7c63ccee917b3ae48324b61659c7e32d', None, None, None)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first 5 rows of the lexicon table\n",
    "%sql SELECT * FROM stixd_corpus.lexicon LIMIT 5;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+mysqlconnector://your_username:***@localhost:3306/stixd_corpus\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>obj_id</th>\n",
       "            <th>type</th>\n",
       "            <th>created_by_ref</th>\n",
       "            <th>description</th>\n",
       "            <th>spec_version</th>\n",
       "            <th>created</th>\n",
       "            <th>modified</th>\n",
       "            <th>revoked</th>\n",
       "            <th>labels</th>\n",
       "            <th>confidence</th>\n",
       "            <th>lang</th>\n",
       "            <th>external_references</th>\n",
       "            <th>object_marking_refs</th>\n",
       "            <th>granular_markings</th>\n",
       "            <th>extensions</th>\n",
       "            <th>derived_from</th>\n",
       "            <th>duplicate_of</th>\n",
       "            <th>related_to</th>\n",
       "            <th>other_properties</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255</td>\n",
       "            <td>x-stixd-clex</td>\n",
       "            <td>user</td>\n",
       "            <td>ACE Common Lexicon Import</td>\n",
       "            <td>2.1</td>\n",
       "            <td>2024-08-17 12:15:54</td>\n",
       "            <td>2024-08-17 12:15:54</td>\n",
       "            <td>0</td>\n",
       "            <td>[&quot;lexicon&quot;]</td>\n",
       "            <td>100</td>\n",
       "            <td>en</td>\n",
       "            <td>[]</td>\n",
       "            <td>[]</td>\n",
       "            <td>[]</td>\n",
       "            <td>[]</td>\n",
       "            <td>None</td>\n",
       "            <td>None</td>\n",
       "            <td>[]</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255', 'x-stixd-clex', 'user', 'ACE Common Lexicon Import', '2.1', datetime.datetime(2024, 8, 17, 12, 15, 54), datetime.datetime(2024, 8, 17, 12, 15, 54), 0, '[\"lexicon\"]', 100, 'en', '[]', '[]', '[]', '[]', None, None, '[]', None)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first 5 rows of the stix_objects table\n",
    "%sql SELECT * FROM stixd_corpus.stix_objects LIMIT 5;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+mysqlconnector://your_username:***@localhost:3306/stixd_corpus\n",
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>obj_id</th>\n",
       "            <th>lex_id</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255</td>\n",
       "            <td>2</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255</td>\n",
       "            <td>3</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255</td>\n",
       "            <td>4</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255</td>\n",
       "            <td>5</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255', 1),\n",
       " ('x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255', 2),\n",
       " ('x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255', 3),\n",
       " ('x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255', 4),\n",
       " ('x-stixd-clex--6052abaa-8eaf-4378-86b6-b7a368673255', 5)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first 5 rows of the obj_lex_jt junction table\n",
    "%sql SELECT * FROM stixd_corpus.obj_lex_jt LIMIT 5;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution via Web Form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have not yet figured out how to run the Flask API in a notebook. However, we can run the Flask API locally by following these steps:\n",
    "\n",
    "1. Navigate to the directory containing the `api.py` file.\n",
    "1. Activate the virtual environment.\n",
    "    - On Windows: `.venv\\Scripts\\activate`\n",
    "    - On macOS/Linux: `source .venv/bin/activate`\n",
    "1. Install dependencies, if necessary\n",
    "    - `pip install -r requirements.txt`\n",
    "1. Run the Flask API\n",
    "    - `python api.py`\n",
    "1. Access the web form at `http://localhost:5000/`\n",
    "1. When finished, stop the Flask API by pressing `Ctrl+C` in the terminal.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
